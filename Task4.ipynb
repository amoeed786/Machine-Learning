{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:].values\n",
    "y = df.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([(\"mainroad\",OneHotEncoder(),[4]),(\"guestroom\",OneHotEncoder(),[5]),(\"basement\",OneHotEncoder(),[6]),(\"hotwaterheating\",OneHotEncoder(),[7]),(\"airconditioning\",OneHotEncoder(),[8]),(\"prefarea\",OneHotEncoder(),[10]),(\"furnishingstatus\",OneHotEncoder(),[11])],remainder=\"passthrough\")\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 1.0, ..., 2, 3, 2],\n",
       "       [1.0, 1.0, 0.0, ..., 4, 4, 3],\n",
       "       [0.0, 0.0, 1.0, ..., 2, 2, 2],\n",
       "       ...,\n",
       "       [0.0, 1.0, 0.0, ..., 1, 1, 0],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 1, 0],\n",
       "       [0.0, 1.0, 0.0, ..., 1, 2, 0]], dtype=object)"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "X = np.append(arr=np.ones((545, 1)).astype(int), values=X, axis=1)\n",
    "X_opt = X[:,[0,1,2,3,4,5,6,7,8,9,10,11,12]]\n",
    "regressor_ols = sm.OLS(y, X_opt.tolist()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.653</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.647</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   111.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>6.87e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:11:35</td>     <th>  Log-Likelihood:    </th> <td> -8355.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   545</td>      <th>  AIC:               </th> <td>1.673e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   535</td>      <th>  BIC:               </th> <td>1.677e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  2.34e+05</td> <td> 8.25e+04</td> <td>    2.835</td> <td> 0.005</td> <td> 7.19e+04</td> <td> 3.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  2.34e+05</td> <td> 8.25e+04</td> <td>    2.835</td> <td> 0.005</td> <td> 7.19e+04</td> <td> 3.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 8.486e+05</td> <td> 1.11e+05</td> <td>    7.651</td> <td> 0.000</td> <td> 6.31e+05</td> <td> 1.07e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-2.803e+05</td> <td> 6.16e+04</td> <td>   -4.549</td> <td> 0.000</td> <td>-4.01e+05</td> <td>-1.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 5.143e+05</td> <td> 7.97e+04</td> <td>    6.455</td> <td> 0.000</td> <td> 3.58e+05</td> <td> 6.71e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 2.736e+05</td> <td> 8.34e+04</td> <td>    3.283</td> <td> 0.001</td> <td>  1.1e+05</td> <td> 4.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 2.062e+05</td> <td> 7.04e+04</td> <td>    2.927</td> <td> 0.004</td> <td> 6.78e+04</td> <td> 3.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>-2.458e+05</td> <td> 7.16e+04</td> <td>   -3.431</td> <td> 0.001</td> <td>-3.86e+05</td> <td>-1.05e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  257.8313</td> <td>   24.610</td> <td>   10.477</td> <td> 0.000</td> <td>  209.488</td> <td>  306.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1.319e+05</td> <td> 7.42e+04</td> <td>    1.777</td> <td> 0.076</td> <td>-1.39e+04</td> <td> 2.78e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> 1.057e+06</td> <td> 1.06e+05</td> <td>    9.931</td> <td> 0.000</td> <td> 8.48e+05</td> <td> 1.27e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 4.191e+05</td> <td> 6.34e+04</td> <td>    6.609</td> <td> 0.000</td> <td> 2.95e+05</td> <td> 5.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 3.068e+05</td> <td> 6.02e+04</td> <td>    5.094</td> <td> 0.000</td> <td> 1.88e+05</td> <td> 4.25e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>103.351</td> <th>  Durbin-Watson:     </th> <td>   1.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 250.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.974</td>  <th>  Prob(JB):          </th> <td>4.52e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.689</td>  <th>  Cond. No.          </th> <td>6.34e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.23e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.653   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.647   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     111.9   \\\\\n",
       "\\textbf{Date:}             & Wed, 20 Mar 2024 & \\textbf{  Prob (F-statistic):} & 6.87e-117   \\\\\n",
       "\\textbf{Time:}             &     23:11:35     & \\textbf{  Log-Likelihood:    } &   -8355.1   \\\\\n",
       "\\textbf{No. Observations:} &         545      & \\textbf{  AIC:               } & 1.673e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         535      & \\textbf{  BIC:               } & 1.677e+04   \\\\\n",
       "\\textbf{Df Model:}         &           9      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &     2.34e+05  &     8.25e+04     &     2.835  &         0.005        &     7.19e+04    &     3.96e+05     \\\\\n",
       "\\textbf{x1}    &     2.34e+05  &     8.25e+04     &     2.835  &         0.005        &     7.19e+04    &     3.96e+05     \\\\\n",
       "\\textbf{x2}    &    8.486e+05  &     1.11e+05     &     7.651  &         0.000        &     6.31e+05    &     1.07e+06     \\\\\n",
       "\\textbf{x3}    &   -2.803e+05  &     6.16e+04     &    -4.549  &         0.000        &    -4.01e+05    &    -1.59e+05     \\\\\n",
       "\\textbf{x4}    &    5.143e+05  &     7.97e+04     &     6.455  &         0.000        &     3.58e+05    &     6.71e+05     \\\\\n",
       "\\textbf{x5}    &    2.736e+05  &     8.34e+04     &     3.283  &         0.001        &      1.1e+05    &     4.37e+05     \\\\\n",
       "\\textbf{x6}    &    2.062e+05  &     7.04e+04     &     2.927  &         0.004        &     6.78e+04    &     3.45e+05     \\\\\n",
       "\\textbf{x7}    &   -2.458e+05  &     7.16e+04     &    -3.431  &         0.001        &    -3.86e+05    &    -1.05e+05     \\\\\n",
       "\\textbf{x8}    &     257.8313  &       24.610     &    10.477  &         0.000        &      209.488    &      306.175     \\\\\n",
       "\\textbf{x9}    &    1.319e+05  &     7.42e+04     &     1.777  &         0.076        &    -1.39e+04    &     2.78e+05     \\\\\n",
       "\\textbf{x10}   &    1.057e+06  &     1.06e+05     &     9.931  &         0.000        &     8.48e+05    &     1.27e+06     \\\\\n",
       "\\textbf{x11}   &    4.191e+05  &     6.34e+04     &     6.609  &         0.000        &     2.95e+05    &     5.44e+05     \\\\\n",
       "\\textbf{x12}   &    3.068e+05  &     6.02e+04     &     5.094  &         0.000        &     1.88e+05    &     4.25e+05     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 103.351 & \\textbf{  Durbin-Watson:     } &    1.230  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  250.268  \\\\\n",
       "\\textbf{Skew:}          &   0.974 & \\textbf{  Prob(JB):          } & 4.52e-55  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.689 & \\textbf{  Cond. No.          } & 6.34e+19  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 4.23e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.653\n",
       "Model:                            OLS   Adj. R-squared:                  0.647\n",
       "Method:                 Least Squares   F-statistic:                     111.9\n",
       "Date:                Wed, 20 Mar 2024   Prob (F-statistic):          6.87e-117\n",
       "Time:                        23:11:35   Log-Likelihood:                -8355.1\n",
       "No. Observations:                 545   AIC:                         1.673e+04\n",
       "Df Residuals:                     535   BIC:                         1.677e+04\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        2.34e+05   8.25e+04      2.835      0.005    7.19e+04    3.96e+05\n",
       "x1           2.34e+05   8.25e+04      2.835      0.005    7.19e+04    3.96e+05\n",
       "x2          8.486e+05   1.11e+05      7.651      0.000    6.31e+05    1.07e+06\n",
       "x3         -2.803e+05   6.16e+04     -4.549      0.000   -4.01e+05   -1.59e+05\n",
       "x4          5.143e+05   7.97e+04      6.455      0.000    3.58e+05    6.71e+05\n",
       "x5          2.736e+05   8.34e+04      3.283      0.001     1.1e+05    4.37e+05\n",
       "x6          2.062e+05   7.04e+04      2.927      0.004    6.78e+04    3.45e+05\n",
       "x7         -2.458e+05   7.16e+04     -3.431      0.001   -3.86e+05   -1.05e+05\n",
       "x8           257.8313     24.610     10.477      0.000     209.488     306.175\n",
       "x9          1.319e+05   7.42e+04      1.777      0.076   -1.39e+04    2.78e+05\n",
       "x10         1.057e+06   1.06e+05      9.931      0.000    8.48e+05    1.27e+06\n",
       "x11         4.191e+05   6.34e+04      6.609      0.000    2.95e+05    5.44e+05\n",
       "x12         3.068e+05   6.02e+04      5.094      0.000    1.88e+05    4.25e+05\n",
       "==============================================================================\n",
       "Omnibus:                      103.351   Durbin-Watson:                   1.230\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              250.268\n",
       "Skew:                           0.974   Prob(JB):                     4.52e-55\n",
       "Kurtosis:                       5.689   Cond. No.                     6.34e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.23e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.535</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.529</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   88.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>4.38e-85</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:11:35</td>     <th>  Log-Likelihood:    </th> <td> -8435.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   545</td>      <th>  AIC:               </th> <td>1.689e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   537</td>      <th>  BIC:               </th> <td>1.692e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.677e+05</td> <td>  6.4e+04</td> <td>    7.303</td> <td> 0.000</td> <td> 3.42e+05</td> <td> 5.93e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 4.677e+05</td> <td>  6.4e+04</td> <td>    7.303</td> <td> 0.000</td> <td> 3.42e+05</td> <td> 5.93e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 4.677e+05</td> <td>  6.4e+04</td> <td>    7.303</td> <td> 0.000</td> <td> 3.42e+05</td> <td> 5.93e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 1.116e+06</td> <td> 1.26e+05</td> <td>    8.849</td> <td> 0.000</td> <td> 8.68e+05</td> <td> 1.36e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -3.07e+05</td> <td> 6.69e+04</td> <td>   -4.588</td> <td> 0.000</td> <td>-4.38e+05</td> <td>-1.76e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 7.747e+05</td> <td> 7.88e+04</td> <td>    9.829</td> <td> 0.000</td> <td>  6.2e+05</td> <td> 9.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 4.679e+05</td> <td>  9.1e+04</td> <td>    5.143</td> <td> 0.000</td> <td> 2.89e+05</td> <td> 6.47e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 2.959e+05</td> <td> 7.79e+04</td> <td>    3.798</td> <td> 0.000</td> <td> 1.43e+05</td> <td> 4.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-2.961e+05</td> <td> 8.05e+04</td> <td>   -3.677</td> <td> 0.000</td> <td>-4.54e+05</td> <td>-1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 2.167e+05</td> <td> 8.54e+04</td> <td>    2.536</td> <td> 0.012</td> <td> 4.88e+04</td> <td> 3.85e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> 1.265e+06</td> <td> 1.22e+05</td> <td>   10.396</td> <td> 0.000</td> <td> 1.03e+06</td> <td>  1.5e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 3.589e+05</td> <td> 7.31e+04</td> <td>    4.913</td> <td> 0.000</td> <td> 2.15e+05</td> <td> 5.02e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>118.191</td> <th>  Durbin-Watson:     </th> <td>   1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 298.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.091</td>  <th>  Prob(JB):          </th> <td>1.59e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.895</td>  <th>  Cond. No.          </th> <td>3.79e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.01e-34. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.535   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.529   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     88.19   \\\\\n",
       "\\textbf{Date:}             & Wed, 20 Mar 2024 & \\textbf{  Prob (F-statistic):} &  4.38e-85   \\\\\n",
       "\\textbf{Time:}             &     23:11:35     & \\textbf{  Log-Likelihood:    } &   -8435.0   \\\\\n",
       "\\textbf{No. Observations:} &         545      & \\textbf{  AIC:               } & 1.689e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         537      & \\textbf{  BIC:               } & 1.692e+04   \\\\\n",
       "\\textbf{Df Model:}         &           7      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.677e+05  &      6.4e+04     &     7.303  &         0.000        &     3.42e+05    &     5.93e+05     \\\\\n",
       "\\textbf{x1}    &    4.677e+05  &      6.4e+04     &     7.303  &         0.000        &     3.42e+05    &     5.93e+05     \\\\\n",
       "\\textbf{x2}    &    4.677e+05  &      6.4e+04     &     7.303  &         0.000        &     3.42e+05    &     5.93e+05     \\\\\n",
       "\\textbf{x3}    &    1.116e+06  &     1.26e+05     &     8.849  &         0.000        &     8.68e+05    &     1.36e+06     \\\\\n",
       "\\textbf{x4}    &    -3.07e+05  &     6.69e+04     &    -4.588  &         0.000        &    -4.38e+05    &    -1.76e+05     \\\\\n",
       "\\textbf{x5}    &    7.747e+05  &     7.88e+04     &     9.829  &         0.000        &      6.2e+05    &     9.29e+05     \\\\\n",
       "\\textbf{x6}    &    4.679e+05  &      9.1e+04     &     5.143  &         0.000        &     2.89e+05    &     6.47e+05     \\\\\n",
       "\\textbf{x7}    &    2.959e+05  &     7.79e+04     &     3.798  &         0.000        &     1.43e+05    &     4.49e+05     \\\\\n",
       "\\textbf{x8}    &   -2.961e+05  &     8.05e+04     &    -3.677  &         0.000        &    -4.54e+05    &    -1.38e+05     \\\\\n",
       "\\textbf{x9}    &    2.167e+05  &     8.54e+04     &     2.536  &         0.012        &     4.88e+04    &     3.85e+05     \\\\\n",
       "\\textbf{x10}   &    1.265e+06  &     1.22e+05     &    10.396  &         0.000        &     1.03e+06    &      1.5e+06     \\\\\n",
       "\\textbf{x11}   &    3.589e+05  &     7.31e+04     &     4.913  &         0.000        &     2.15e+05    &     5.02e+05     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 118.191 & \\textbf{  Durbin-Watson:     } &    1.024  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  298.414  \\\\\n",
       "\\textbf{Skew:}          &   1.091 & \\textbf{  Prob(JB):          } & 1.59e-65  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.895 & \\textbf{  Cond. No.          } & 3.79e+18  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 7.01e-34. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.535\n",
       "Model:                            OLS   Adj. R-squared:                  0.529\n",
       "Method:                 Least Squares   F-statistic:                     88.19\n",
       "Date:                Wed, 20 Mar 2024   Prob (F-statistic):           4.38e-85\n",
       "Time:                        23:11:35   Log-Likelihood:                -8435.0\n",
       "No. Observations:                 545   AIC:                         1.689e+04\n",
       "Df Residuals:                     537   BIC:                         1.692e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.677e+05    6.4e+04      7.303      0.000    3.42e+05    5.93e+05\n",
       "x1          4.677e+05    6.4e+04      7.303      0.000    3.42e+05    5.93e+05\n",
       "x2          4.677e+05    6.4e+04      7.303      0.000    3.42e+05    5.93e+05\n",
       "x3          1.116e+06   1.26e+05      8.849      0.000    8.68e+05    1.36e+06\n",
       "x4          -3.07e+05   6.69e+04     -4.588      0.000   -4.38e+05   -1.76e+05\n",
       "x5          7.747e+05   7.88e+04      9.829      0.000     6.2e+05    9.29e+05\n",
       "x6          4.679e+05    9.1e+04      5.143      0.000    2.89e+05    6.47e+05\n",
       "x7          2.959e+05   7.79e+04      3.798      0.000    1.43e+05    4.49e+05\n",
       "x8         -2.961e+05   8.05e+04     -3.677      0.000   -4.54e+05   -1.38e+05\n",
       "x9          2.167e+05   8.54e+04      2.536      0.012    4.88e+04    3.85e+05\n",
       "x10         1.265e+06   1.22e+05     10.396      0.000    1.03e+06     1.5e+06\n",
       "x11         3.589e+05   7.31e+04      4.913      0.000    2.15e+05    5.02e+05\n",
       "==============================================================================\n",
       "Omnibus:                      118.191   Durbin-Watson:                   1.024\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              298.414\n",
       "Skew:                           1.091   Prob(JB):                     1.59e-65\n",
       "Kurtosis:                       5.895   Cond. No.                     3.79e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.01e-34. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "X = np.append(arr=np.ones((545, 1)).astype(int), values=X, axis=1)\n",
    "X_opt = X[:,[0,1,2,3,4,5,6,7,8,10,11,12]]\n",
    "regressor_ols = sm.OLS(y, X_opt.tolist()).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.0558608  -0.55323817\n",
      "  -0.90765959]\n",
      " [ 0.          0.          0.         ... -1.27432452 -0.55323817\n",
      "  -0.90765959]\n",
      " [ 0.          0.          0.         ... -1.27432452 -0.55323817\n",
      "  -0.90765959]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.0558608   1.55459927\n",
      "   1.41326862]\n",
      " [ 0.          0.          0.         ... -1.27432452 -0.55323817\n",
      "  -0.90765959]\n",
      " [ 0.          0.          0.         ...  0.0558608   1.55459927\n",
      "   2.57373272]]\n",
      "[[ 0.          0.          0.         ...  1.44943654  1.18232428\n",
      "   0.16014368]\n",
      " [ 0.          0.          0.         ...  0.02603778  1.18232428\n",
      "   1.30203774]\n",
      " [ 0.          0.          0.         ... -1.39736098 -0.61305703\n",
      "  -0.98175038]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  1.44943654  2.97770559\n",
      "   0.16014368]\n",
      " [ 0.          0.          0.         ...  0.02603778 -0.61305703\n",
      "   0.16014368]\n",
      " [ 0.          0.          0.         ...  0.02603778  1.18232428\n",
      "   0.16014368]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "print(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_tree = DecisionTreeRegressor(random_state=0)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5238333.33333333,  6293000.        ,  3933300.        ,\n",
       "        4520833.33333333,  4128600.        ,  3380000.        ,\n",
       "        4477666.66666667,  3920000.        ,  2953517.24137931,\n",
       "        4128600.        , 10850000.        ,  2953517.24137931,\n",
       "        2971500.        ,  4090800.        ,  3226000.        ,\n",
       "        4200000.        ,  3701833.33333333,  3777666.66666667,\n",
       "        3226000.        ,  3933300.        ,  7180833.33333333,\n",
       "        5845000.        ,  2953517.24137931,  3500000.        ,\n",
       "        4960454.54545455,  9240000.        ,  2953517.24137931,\n",
       "        5628000.        ,  6352500.        ,  3701833.33333333,\n",
       "        8855000.        ,  3226000.        ,  6352500.        ,\n",
       "        4090800.        ,  2721250.        ,  5187000.        ,\n",
       "        4090800.        ,  3360000.        ,  3867500.        ,\n",
       "        5628000.        ,  4960454.54545455,  2971500.        ,\n",
       "        6293000.        ,  4313750.        ,  3933300.        ,\n",
       "        2971500.        ,  6772500.        ,  3651666.66666667,\n",
       "        2953517.24137931,  2953517.24137931,  5775000.        ,\n",
       "        2953517.24137931,  3983500.        ,  4520833.33333333,\n",
       "        2721250.        ,  4128600.        ,  8463000.        ,\n",
       "        3226000.        ,  3651666.66666667,  2953517.24137931,\n",
       "        3999333.33333333,  5238333.33333333,  4893000.        ,\n",
       "        2971500.        ,  3500000.        ,  4090800.        ,\n",
       "        2590000.        ,  3226000.        ,  2852500.        ,\n",
       "        5697125.        ,  3430000.        ,  5873000.        ,\n",
       "        3983500.        ,  6230000.        ,  2971500.        ,\n",
       "        4960000.        ,  4090800.        ,  4760000.        ,\n",
       "        4477666.66666667,  5897500.        ,  6293000.        ,\n",
       "        4090800.        ,  6020000.        ,  6125000.        ,\n",
       "        3226000.        ,  4200000.        ,  3380000.        ,\n",
       "        4090800.        ,  6293000.        ,  4200000.        ,\n",
       "        3651666.66666667,  4477666.66666667,  3983500.        ,\n",
       "        4520833.33333333, 10150000.        ,  6825000.        ,\n",
       "        5600000.        ,  5775000.        ,  6125000.        ,\n",
       "        5950000.        ,  4090800.        ,  8050000.        ,\n",
       "        4357500.        ,  4200000.        ,  3651666.66666667,\n",
       "        4305000.        ,  7210000.        ,  5187000.        ,\n",
       "        6020000.        ,  7663985.        ,  5187000.        ,\n",
       "        4477666.66666667,  3500000.        ,  3226000.        ,\n",
       "        4090800.        ,  3226000.        ,  3380000.        ,\n",
       "        3380000.        ,  4960454.54545455,  4090800.        ,\n",
       "        2953517.24137931,  4128600.        ,  4090800.        ,\n",
       "        4205600.        ,  6895000.        ,  4960454.54545455,\n",
       "        6160000.        ,  3380000.        ,  3920000.        ,\n",
       "        6895000.        ,  4090800.        ,  5740000.        ,\n",
       "        5600000.        ,  4340000.        ,  3226000.        ,\n",
       "        2953517.24137931,  4960454.54545455,  5187000.        ,\n",
       "        3933300.        ,  4778200.        ,  3933300.        ,\n",
       "        4313750.        ,  4520833.33333333,  6125000.        ,\n",
       "        2953517.24137931,  2953517.24137931,  8855000.        ,\n",
       "        5115833.33333333,  4778200.        ,  4960000.        ,\n",
       "        3675000.        ,  3226000.        ,  4778200.        ,\n",
       "        2905000.        ,  4090800.        ,  5460000.        ,\n",
       "       10255000.        ,  5843250.        ,  5775000.        ,\n",
       "        1960000.        ,  3983500.        ,  4200000.        ,\n",
       "        4090800.        ,  5115833.33333333])"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "n = len(X_test) \n",
    "p = X_test.shape[1] \n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1086845.273084079\n",
      "Mean Squared Error: 2510212714158.0884\n",
      "R-Squared: 0.41709598812820214\n",
      "Adjusted R-Squared: 0.37077249049600625\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-Squared:\", r_squared)\n",
    "print(\"Adjusted R-Squared:\", adjusted_r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
