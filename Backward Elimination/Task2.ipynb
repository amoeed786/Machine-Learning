{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Student_Performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
       "0              7               99                        Yes            9   \n",
       "1              4               82                         No            4   \n",
       "2              8               51                        Yes            7   \n",
       "3              5               52                        Yes            5   \n",
       "4              7               75                         No            8   \n",
       "\n",
       "   Sample Question Papers Practiced  Performance Index  \n",
       "0                                 1               91.0  \n",
       "1                                 2               65.0  \n",
       "2                                 2               45.0  \n",
       "3                                 2               36.0  \n",
       "4                                 5               66.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([91., 65., 45., ..., 74., 95., 64.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:5].values\n",
    "y = df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([(\"Extracurricular Activities\",OneHotEncoder(),[2])],remainder=\"passthrough\")\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 7, 99, 9, 1],\n",
       "       [1.0, 0.0, 4, 82, 4, 2],\n",
       "       [0.0, 1.0, 8, 51, 7, 2],\n",
       "       ...,\n",
       "       [0.0, 1.0, 6, 83, 8, 5],\n",
       "       [0.0, 1.0, 9, 97, 7, 0],\n",
       "       [1.0, 0.0, 7, 74, 8, 1]], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 7, 99, 9, 1],\n",
       "       [0.0, 4, 82, 4, 2],\n",
       "       [1.0, 8, 51, 7, 2],\n",
       "       ...,\n",
       "       [1.0, 6, 83, 8, 5],\n",
       "       [1.0, 9, 97, 7, 0],\n",
       "       [0.0, 7, 74, 8, 1]], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "X = np.append(arr=np.ones((10000, 1)).astype(int), values=X, axis=1)\n",
    "X_opt = X[:,[0,1,2,3,4,5]]\n",
    "regressor_ols = sm.OLS(y, X_opt.tolist()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.988</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.043e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Mar 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:18:05</td>     <th>  Log-Likelihood:    </th> <td> -21665.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>4.334e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9995</td>      <th>  BIC:               </th> <td>4.338e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -16.6200</td> <td>    0.064</td> <td> -259.912</td> <td> 0.000</td> <td>  -16.745</td> <td>  -16.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -16.6200</td> <td>    0.064</td> <td> -259.912</td> <td> 0.000</td> <td>  -16.745</td> <td>  -16.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.6274</td> <td>    0.042</td> <td>   14.845</td> <td> 0.000</td> <td>    0.545</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    2.8567</td> <td>    0.008</td> <td>  350.124</td> <td> 0.000</td> <td>    2.841</td> <td>    2.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.0187</td> <td>    0.001</td> <td>  836.215</td> <td> 0.000</td> <td>    1.016</td> <td>    1.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.4819</td> <td>    0.012</td> <td>   38.678</td> <td> 0.000</td> <td>    0.458</td> <td>    0.506</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.220</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.330</td> <th>  Jarque-Bera (JB):  </th> <td>   2.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.002</td> <th>  Prob(JB):          </th> <td>   0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.074</td> <th>  Cond. No.          </th> <td>9.82e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.38e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.988   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.988   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 2.043e+05   \\\\\n",
       "\\textbf{Date:}             & Wed, 20 Mar 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     22:18:05     & \\textbf{  Log-Likelihood:    } &   -21665.   \\\\\n",
       "\\textbf{No. Observations:} &       10000      & \\textbf{  AIC:               } & 4.334e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        9995      & \\textbf{  BIC:               } & 4.338e+04   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &     -16.6200  &        0.064     &  -259.912  &         0.000        &      -16.745    &      -16.495     \\\\\n",
       "\\textbf{x1}    &     -16.6200  &        0.064     &  -259.912  &         0.000        &      -16.745    &      -16.495     \\\\\n",
       "\\textbf{x2}    &       0.6274  &        0.042     &    14.845  &         0.000        &        0.545    &        0.710     \\\\\n",
       "\\textbf{x3}    &       2.8567  &        0.008     &   350.124  &         0.000        &        2.841    &        2.873     \\\\\n",
       "\\textbf{x4}    &       1.0187  &        0.001     &   836.215  &         0.000        &        1.016    &        1.021     \\\\\n",
       "\\textbf{x5}    &       0.4819  &        0.012     &    38.678  &         0.000        &        0.458    &        0.506     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.220 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.330 & \\textbf{  Jarque-Bera (JB):  } &    2.264  \\\\\n",
       "\\textbf{Skew:}          &  0.002 & \\textbf{  Prob(JB):          } &    0.322  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.074 & \\textbf{  Cond. No.          } & 9.82e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 5.38e-27. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.988\n",
       "Model:                            OLS   Adj. R-squared:                  0.988\n",
       "Method:                 Least Squares   F-statistic:                 2.043e+05\n",
       "Date:                Wed, 20 Mar 2024   Prob (F-statistic):               0.00\n",
       "Time:                        22:18:05   Log-Likelihood:                -21665.\n",
       "No. Observations:               10000   AIC:                         4.334e+04\n",
       "Df Residuals:                    9995   BIC:                         4.338e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -16.6200      0.064   -259.912      0.000     -16.745     -16.495\n",
       "x1           -16.6200      0.064   -259.912      0.000     -16.745     -16.495\n",
       "x2             0.6274      0.042     14.845      0.000       0.545       0.710\n",
       "x3             2.8567      0.008    350.124      0.000       2.841       2.873\n",
       "x4             1.0187      0.001    836.215      0.000       1.016       1.021\n",
       "x5             0.4819      0.012     38.678      0.000       0.458       0.506\n",
       "==============================================================================\n",
       "Omnibus:                        2.220   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.330   Jarque-Bera (JB):                2.264\n",
       "Skew:                           0.002   Prob(JB):                        0.322\n",
       "Kurtosis:                       3.074   Cond. No.                     9.82e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.38e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          1.01962103 ...  1.69543433 -0.31944271\n",
      "  -1.26226064]\n",
      " [ 0.          0.          1.01962103 ...  1.17637842  1.44869036\n",
      "  -0.56482402]\n",
      " [ 0.          0.         -0.98075655 ... -0.72682657 -0.31944271\n",
      "  -1.26226064]\n",
      " ...\n",
      " [ 0.          0.         -0.98075655 ... -1.24588248  0.26993498\n",
      "   0.4813309 ]\n",
      " [ 0.          0.         -0.98075655 ... -1.30355536  1.44869036\n",
      "  -1.61097894]\n",
      " [ 0.          0.         -0.98075655 ... -1.36122824 -0.31944271\n",
      "   0.4813309 ]]\n",
      "[[ 0.          0.         -1.01072417 ... -0.00459332  0.88347388\n",
      "  -0.87220784]\n",
      " [ 0.          0.          0.98938962 ... -1.33069816 -1.47875574\n",
      "   1.22248744]\n",
      " [ 0.          0.          0.98938962 ... -0.75413084  0.29291647\n",
      "   0.1751398 ]\n",
      " ...\n",
      " [ 0.          0.          0.98938962 ... -1.2153847  -0.29764093\n",
      "  -0.17397608]\n",
      " [ 0.          0.          0.98938962 ...  0.97557113  1.47403128\n",
      "   0.1751398 ]\n",
      " [ 0.          0.          0.98938962 ... -1.50366836 -0.29764093\n",
      "  -0.17397608]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "print(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.23214673, 23.02760097, 48.47817539, ..., 33.91378637,\n",
       "       68.35399964, 31.72323747])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "n = len(X_test) \n",
    "p = X_test.shape[1] \n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.6849362572964255\n",
      "Mean Squared Error: 4.410298166917474\n",
      "R-Squared: 0.9880821988936449\n",
      "Adjusted R-Squared: 0.9880543163375806\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-Squared:\", r_squared)\n",
    "print(\"Adjusted R-Squared:\", adjusted_r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
